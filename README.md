# LlamaModelLocal

This is a modified version of the original `LlamaModel.ts` file, tailored to work with Ollama's local endpoint using any model. By adjusting the payload structure, we've made the necessary updates to ensure compatibility with Ollama's API, allowing you to seamlessly integrate natural language processing into your bot, all while bypassing the need for Azure subscriptions! 😎

This modification allows the bot to interact with any model installed locally via Ollama, providing a flexible and cost-effective solution for running AI models like Llama3.2 on your local machine. 🖥️🚀
